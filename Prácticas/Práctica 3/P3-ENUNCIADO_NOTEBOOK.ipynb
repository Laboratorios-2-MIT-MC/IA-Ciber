{"cells":[{"cell_type":"markdown","metadata":{"id":"YqSTjxANidTB"},"source":["# **INTELIGENCIA ARTIFICIAL APLICADA A LA CIBERSEGURIDAD**\n","## **PRÁCTICA P3 - BLOQUE III**\n","\n","**INSTRUCCIONES / RECOMENDACIONES**\n","\n","- Se recomienda leer con detalle la descripción de cada una de las celdas.\n","- Las celdas que ya tienen código, se deberán ejecutar directamente. NOTA: algunas celdas con código deberán parametrizarse según lo indicado en cada caso.\n","- Las celdas que están vacías, se completarán con la implementación requerida en el notebook.\n","- No se incluirán más celdas de las establecidas en el presente notebook, por lo que la solución al mismo deberá implementarse exclusivamente en las celdas vacías.\n","- La entrega se realizará vía Moodle. Será necesario subir la solución a este notebook con el nombre: **NOMBRE_GRUPO.ipynb**\n","\n","- **Fecha de Publicación: 08/04/2024**\n","- **Fecha de Entrega: 14/04/2024**\n","- **Test: 15/04/2024**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15cvkrb2idTD"},"outputs":[],"source":["# SETUP\n","\n","!pip3 install transformers\n","!pip3 install einops\n","!pip3 install accelerate\n","!pip3 install unstructured-pytesseract\n","!pip3 install unstructured-inference\n","!pip3 install sentence_transformers\n","!pip3 install chromadb\n","\n","!pip3 install protobuf==3.20.*\n","\n","!pip3 install langchain\n","!pip3 install unstructured\n","!pip3 install pillow_heif\n","!pip3 install cmake\n","!pip3 install pikepdf pypdf\n","!pip3 install python-poppler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Qwkv_jridTE"},"outputs":[],"source":["# IMPORTS\n","\n","from transformers import AutoTokenizer\n","import transformers\n","import torch\n","\n","import langchain\n","\n","langchain.__version__"]},{"cell_type":"markdown","metadata":{"id":"2GNk2VXBidTF"},"source":["## LLM\n","\n","Se deberá parametrizar el modelo LLM según los siguientes atributos:\n","- model_id\n","- max_length\n","- max_new_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3LBfdgzzMln"},"outputs":[],"source":["from langchain import HuggingFacePipeline\n","\n","llm = HuggingFacePipeline.from_model_id(\n","    model_id=,\n","    task=\"text-generation\",\n","    model_kwargs={\n","        \"max_length\": ,\n","        'do_sample': True,\n","        'top_k': 10,\n","        'num_return_sequences': 2,\n","        #'device_map': 'auto',\n","        'trust_remote_code': True,\n","        'torch_dtype': torch.bfloat16\n","    },\n","    pipeline_kwargs={\"max_new_tokens\": },\n","    device=0,\n",")"]},{"cell_type":"markdown","metadata":{"id":"LfwbmBWHidTF"},"source":["## DOCUMENTS & SPLITTER & VECTORSTORE\n","\n","Se deberá construir un sistema RAG sobre un caso de uso de Ciberseguridad, utilizando para ello el modelo LLM especificado. La selección del caso de uso de Ciberseguridad será propuesta por el alumn@, estableciendo el documento PDF base (**pdf_base**) para realizar posteriormente las consultas al modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtKkcdMYzMln"},"outputs":[],"source":["# INDEXING\n","\n","from langchain.document_loaders import OnlinePDFLoader\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.chains import ConversationalRetrievalChain"]},{"cell_type":"code","source":["# 1. LOAD\n","pdf_base =\n","loader = OnlinePDFLoader(pdf_base)\n","document = loader.load()\n","\n","# 2. SPLIT\n","text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n","documents = text_splitter.split_documents(document)\n","\n","# 3. EMBED & STORE\n","embeddings = HuggingFaceEmbeddings()\n","vectorstore = Chroma.from_documents(documents, embeddings)\n","\n","# RETRIEVAL & GENERATION\n","qa = ConversationalRetrievalChain.from_llm(\n","    llm,\n","    vectorstore.as_retriever(),\n","    return_source_documents=True,\n",")"],"metadata":{"id":"xFpyB50pyDqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E3POV-7BidTG"},"source":["## QUESTION TO LLM = MY_QUERY + CONTEXT_from_VECTORSTORE -> ANSWER FROM LLM\n","\n","Se deberá generar un catálogo de 10 prompts de consultas sobre el sistema RAG generado, utilizando para ello la variable **my_query**. Los prompts generados deberán obtener respuestas del modelo LLM con una calidad adecuada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKGRwVPhzMln"},"outputs":[],"source":["my_query ="]},{"cell_type":"code","source":["result = qa({\"question\": my_query, \"chat_history\": chat_history})\n","print(result[\"answer\"])"],"metadata":{"id":"qIVgDhaQyYpi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conclusiones\n","\n","Detalle las conclusiones extraídas del presente estudio sobre LLMs y sistemas RAG."],"metadata":{"id":"dQ6jLhRruTkZ"}},{"cell_type":"markdown","source":["*# Escriba aquí las conclusiones*"],"metadata":{"id":"RB1_o5G9ubaY"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}